Vi kan inte skicka en avbildning av emoji till brunnen eftersom den inte anv칛ndas f칬r att visa dess k칛nslo eftersom Ansikts-API. S친 f칬r varje emoji jag beh칬vde en m칛nsklig proxy mig.

Jag b칬rjade med bilder av sj칛lv _korrekt_ frihandsbilden varje emoji och anv칛nds den _k칛nslom칛ssig punkt_ f칬r avbildningen som proxy f칬r emoji. F칬r att g칬ra det intressanta jag ocks친 valde personer fr친n mitt team och kopplade emojis samt, t.ex:

![Team Moji](/media-drafts/team.jpg)

Du kan se en lista 칬ver proxy-avbildningar f칬r varje emoji i den `bin/proxy-images` mappen i exempelkoden som 칛r associerade med den h칛r sj칛lvstudien.

## <a name="goal"></a>M친l

I det h칛r kapitlet genererar du n칬dv칛ndiga autentiseringsnycklar s친 att du kan anv칛nda Ansikts-API i Azure och sedan anv칛nda Ansikts-API f칬r att kalibrera alla emojis med hj칛lp av proxyn avbildningar av mig.

## <a name="learning-objectives"></a>Utbildningsm친l

- Generera API-nycklar f칬r anv칛ndning med Cognitive Services.
- Hur du k칬r avbildningar via Ansikts-API och extrahera k칛nslo-information.

## <a name="generate-an-azure-face-api-key"></a>Skapa en Azure Ansikts-API-nyckel

Om du vill anv칛nda Ansikts-API f칬r Azure beh칬ver vi en autentiseringsnyckel.

Det snabbaste s칛ttet att h칛mta en nyckel 칛r att g친 칬ver till https://azure.microsoft.com/try/cognitive-services/?api=face-api och registrering av Ansikts-API-utv칛rderingsversionen.

N칛r du registrera dig f친r du n친gra delarna av information som du beh칬ver f칬r att lagra f칬r senare.

1. H칛mta den _endpoint_. Det b칬r se ut ungef칛r som https://westcentralus.api.cognitive.microsoft.com/face/v1.0

2. Den visar tv친 API-nycklar, store en av dem f칬r anv칛ndning senare ingen (det spelar roll vilken)

## <a name="setup-the-environment-variables"></a>Konfigurera milj칬variabler

Skriptet kalibrering beh칬ver veta ditt Ansikts-API-URL och nyckel f칬r att g칬ra r칛tt-anrop, i st칛llet f칬r att h친rdkoda dessa i skriptet som vi ska anv칛nda milj칬variabler, k칬r f칬ljande kommandon i terminalen du f칬rv칛ntar dig att k칬ra programmet:

```bash
export FACE_API_URL=<the-face-api-url>
export FACE_API_KEY=<your-face-api-key>
```

Vi anv칛nder ocks친 ett paket som heter `dotenv` i v친r Node-programmet. Det h칛r paketet ska vi anv칛nda lagra milj칬variablerna lokalt i en fil med namnet `.env`. Den `dotenv` paketet laddas alla variabler i den h칛r filen och visas som milj칬variabler i ditt program.

> **OBS!**
>
> Inte checka in `.env` filerna till k칛llkontroll.

Azure Functions har ett annat s칛tt f칬r hantering av milj칬variabler via sina `local.settings.json` filen, mer om det senare.

## <a name="create-some-proxy-images-for-emojis"></a>Skapa en proxy-avbildningar f칬r emojis

Jag har angett alla avbildningar f칬r proxy sj칛lv, men kan skapa din egen!

F칬r varje emoji i den `bin/proxy-images` mappen, ta en bild av sj칛lv frihandsbilden som emoji och ers칛tta den med din avbildning.

## <a name="try-it-out"></a>Prova

Nu kommer roligt del! Vi kommer att k칬ra var och en av avbildningarna i den `bin/proxy-images` via Ansikts-API f칬r att ber칛kna en k칛nslom칛ssig tidpunkt f칬r den emoji i _k칛nslom칛ssig utrymme_, k칬r:

```bash
node bin/calibrate.js
```

Kommandots utdata b칬r se ut ungef칛r som detta:

```json
...
Processing 游뱁
Processing 游뱂
Processing 游붃
Processing 游땎
Processing 游땑
...
{
    emotiveValues: new EmotivePoint({
        anger: 0,
        contempt: 0.005,
        disgust: 0.001,
        fear: 0,
        happiness: 0,
        neutral: 0.922,
        sadness: 0.071,
        surprise: 0
    }),
    emojiIcon: "游땺"
}
```

Den f칬rsta skriver ut den emoji's 칛r den bearbetning och sedan slutligen skriva ut till konsolen en matris som definierar den `EmotivePoint` av alla emoji. Det h칛r 칛r samma format som matrisen i `shared/mojis.ts`.

Om du har 칛ndrat vissa via proxy bilder kan sedan kopiera utdata fr친n det h칛r skriptet till relevanta avsnitt av `mojis.ts`
