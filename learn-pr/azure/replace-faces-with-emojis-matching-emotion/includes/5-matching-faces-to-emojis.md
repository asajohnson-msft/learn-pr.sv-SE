I det senaste kapitlet l√§rde vi oss att filen `shared/mojis.ts` har en lista med emojis och deras k√§nslom√§ssiga uttryck.

I det h√§r kapitlet g√•r vi igenom resten av koden som vi kommer anv√§nda f√∂r att mappa ett ansikte till en emoji.

Du f√•r l√§ra dig att:

1. Skapa ett skript d√§r du skickar en URL till en ansiktsbild som indata.
2. Utv√§rdera det k√§nslom√§ssiga uttrycket hos ansikten i bilden.
3. Mappa ansiktena i bilden till den emoji som ligger n√§rmast

S√• sm√•ningom kommer vi att implementera den h√§r funktionen som ett Slack-kommando, men nu ska vi b√∂rja med ett enkelt node-skript som du kan k√∂ra p√• kommandoraden, till exempel s√• h√§r:

```bash
node bin/mojify.js <url-of-image-with-face>
```

## <a name="debugging-typescript"></a>Fels√∂ka TypeScript

Vi skriver i TypeScript men k√∂r JavaScript. Det h√§r g√∂r det sv√•rt med fels√∂kningen eftersom vi beh√∂ver ange brytpunkter och fels√∂ka i de transpilerade JavaScript-filerna som kan vara sv√•ra att l√§sa.

Vad vi helst vill √§r att skriva _och_ fels√∂ka i TypeScript.

Den goda nyheten √§r att vi kan g√∂ra det i vs-kod med en gnutta konfigurering.

√ñppna filen `launch.json` med kommandopaletten `Ctrl+P > Debug: Open launch.json`

> TODO: Bild

L√§gg till ett konfigurationsalternativ s√• h√§r:

```json
{
  "type": "node",
  "request": "launch",
  "name": "Mojify",
  "env": {
    "DEBUG": "*"
  },
  "args": [
    "https://pbs.twmedia-drafts.com/profile_images/833970306339446784/83MO53R9_400x400.jpg"
  ],
  "sourceMaps": true,
  "stopOnEntry": false,
  "console": "integratedTerminal",
  "cwd": "${workspaceRoot}",
  "program": "${workspaceRoot}/bin/mojify.js",
  "outFiles": ["${workspaceRoot}/bin/mojify.js"]
}
```

Nu ser du alternativet `Mojify` i fels√∂kningsmenyn som k√∂r mojify-skriptet och skickar en URL som argument. Du kan ange brytpunkter i TypeScript-filen och inspektera variabler direkt d√§rifr√•n.

## <a name="open-up-binmojists"></a>√ñppna `bin/mojis.ts`

Filen √§r redan √§r ifylld med alla n√∂dv√§ndiga importer:

```typescript
require("dotenv").config();
import fetch from "node-fetch";
import { EmotivePoint, Face, Rect } from "../shared/models";
```

`dotenv` √§r en hj√§lpkomponent som l√§ser in inneh√•llet i en .env-fil till projektroten som milj√∂variabler, vilket √§r anv√§ndbart vid utveckling.

`node-fetch` anv√§nds till att skicka http-f√∂rfr√•gningar till API:t f√∂r ansiktsigenk√§nning i Azure.

`EmotivePoint` √§r en hj√§lpklass som beskriver en punkt i _det k√§nslom√§ssiga utrymmet_ ‚Äì vi kommer att diskutera detta mer detaljerat nedan.

`Rect` √§r en hj√§lpklass som beskriver en rektangul√§r form, vi anv√§nder den till att beskriva ett ansiktes position i en bild.

`Face` √§r en hj√§lpklass d√§r rektangel- och k√§nsloinformationen om ett ansikte i en bild kombineras.

Du b√∂r se n√•gra funktionsskelett i mitten av filen:

```typescript
async function getFaces(imageUrl) {
  //TODO
}

async function createMojifiedImage(imageUrl, faces) {
  //TODO
}
```

Det √§r dessa funktioner du kommer att bygga ut i den h√§r lektionen och n√§sta

Mot slutet av filen b√∂r du se f√∂ljande kod:

```typescript
async function main() {
  const [imageUrl] = process.argv.slice(2);
  console.log(imageUrl);
  const faces = await getFaces(imageUrl);
  await createMojifiedImage(imageUrl, faces);
}
main();
```

## <a name="add-the-environment-variables"></a>L√§gg till milj√∂variablerna

Vi ska anropa API:t f√∂r ansiktsigenk√§nning, s√• vi m√•ste anv√§nda de hemliga nycklar och webbadresser vi genererade tidigare. L√§gg till dem √∂verst i filen under importerna:

```typescript
const API_URL = process.env["FACE_API_URL"];
const API_KEY = process.env["FACE_API_KEY"];
```

## <a name="call-the-face-api-with-the-provided-image-and-get-a-response"></a>Anropa API:t f√∂r ansiktsigenk√§nning med den tillhandah√•llna bilden och f√• svar

F√∂r att g√∂ra f√∂rfr√•gningar till API:t f√∂r ansiktsigenk√§nning l√§gger vi till f√∂ljande kod l√§ngst upp i funktionen `getFaces`:

```typescript
let response = await fetch(API_URL, {
  headers: {
    "Ocp-Apim-Subscription-Key": API_KEY,
    "Content-Type": "application/json"
  },
  method: "POST",
  body: JSON.stringify({ url: imageUrl })
});
let resp = await response.json();
console.log(resp);
```

I koden ovan anv√§nds kommandot `fetch` till att skicka en `POST`-f√∂rfr√•gan till API:t f√∂r ansiktsigenk√§nning.

Vi skickar `API_KEY` i rubriken s√• att API:t f√∂r ansiktsigenk√§nning vet att f√∂rfr√•gningen kommer fr√•n oss, annars avvisas den.

Vi skickar den `imageUrl` vi vill att API:t f√∂r ansiktsigenk√§nning ska analysera i br√∂dtexten.

Vi f√•r sedan svaret fr√•n f√∂rfr√•gningen och skriver ut det.

Om du nu k√∂r skriptet med

```bash
node bin/mojify.js <path-to-image>
```

S√• ska json-svaret som returnerades fr√•n bildanalysen skrivas ut.

## <a name="parse-the-responce"></a>Parsa svaret

I emojiber√§kningen m√•ste vi konvertera de ansikten som returnerades i API-svaret till en instans av klassen `Face`.

Vi l√§gger till den h√§r koden direkt efter koden f√∂r API-anropet i funktionen `getFaces`:

```typescript
let faces = [];
for (let f of resp) {
  let scores = new EmotivePoint(f.faceAttributes.emotion);
  let faceRectangle = new Rect(f.faceRectangle);
  let face = new Face(scores, faceRectangle);
  console.log(face.mojiIcon);
  faces.push(face);
}
return faces;
```

- Vi itererar √∂ver alla ansikten som returneras i svaret.
- Vi genererar instanser av `EmotivePoint`, `Rect` och `Face` fr√•n json-svaret.
- N√§r vi skapar `Face`-instansen matchas ansiktet mot en emoji.
- F√∂r att se vilken emoji som matchades skriver vi ut en `mojiicon`.

## <a name="try-it-out"></a>Prova

Om du k√∂r skriptet nu b√∂r det g√∂ra f√∂ljande:

- Skicka den angivna bilden till API:t f√∂r ansiktsigenk√§nning och avg√∂ra de k√§nslouttryck som visas.
- Matcha k√§nslouttryck mot en emojis.
- Skriva ut emojisarna i terminalen.

S√• h√§r:

```bash
node bin/mojify.js <path-to-image>
<path-to-image>
üòï
```
